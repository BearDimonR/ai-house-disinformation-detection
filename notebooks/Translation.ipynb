{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2148007a-3969-43fd-9faf-909b1d0d2cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet transformers sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8141483-5087-4d9c-b92e-011a4e3b915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ac17e9-e216-40e4-95f7-4c277f7642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b0c0921-fa72-4a76-b66f-ab6c69db4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../datasets/train.csv')\n",
    "test_df = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "702c7b8e-f124-4d56-9e87-a9dbc212aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.iloc[:10]['Content'].values.tolist(), train_df.iloc[:10]['Suspicious_Level']\n",
    "X_test = test_df.iloc[:10]['Content'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb5b0e-3a36-4b2c-9930-0f3e4ff600fc",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46399ad2-b75e-4802-8c9c-104b91acb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# nlp_ru = spacy.load('ru_core_news_md', disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# def text_processing(texts):\n",
    "#     processed_texts = []\n",
    "#     for text in texts:\n",
    "#         doc = nlp_ru(text)\n",
    "#         processed_text = \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "#         processed_texts.append(processed_text)\n",
    "#     return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d85cec86-62cf-4efd-95fc-e02fdd86ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danorel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/danorel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the Snowball stemmer for Russian language\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Create a Snowball stemmer for Russian\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "def collapse_dots(input):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", input)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "def process_text(input):\n",
    "    if isinstance(input, str):\n",
    "        input = \" \".join(tokenize.sent_tokenize(input))\n",
    "        input = re.sub(r\"http\\S+\", \"\", input)\n",
    "        input = re.sub(r\"\\n+\", \". \", input)\n",
    "        for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n",
    "            input = re.sub(rf\"\\{symb}\\.\", symb, input)\n",
    "        input = re.sub(\"[^а-яА-Яa-zA-Z0-9!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", input)\n",
    "        input = re.sub(r\"#\\S+\", \"\", input)\n",
    "        input = collapse_dots(input)\n",
    "        input = input.strip()\n",
    "        # input = input.lower()\n",
    "    return input\n",
    "\n",
    "train_df[\"Content_processed\"] = train_df[\"Content\"].apply(process_text)\n",
    "test_df[\"Content_processed\"] = test_df[\"Content\"].apply(process_text)\n",
    "\n",
    "# Tokenize the text using NLTK for Russian language\n",
    "train_df['Content_tokenized'] = train_df['Content_processed'].apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x, language='russian')]))\n",
    "test_df['Content_tokenized'] = test_df['Content_processed'].apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x, language='russian')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fa758-cb89-4c80-81f0-a9d9cef451db",
   "metadata": {},
   "source": [
    "### Translator & Fake detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f91d50-5a8d-459a-9b60-dbc1275504a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = \"Helsinki-NLP/opus-mt-ru-en\"\n",
    "translation_tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "translation_model = AutoModelForSeq2SeqLM.from_pretrained(mname)\n",
    "\n",
    "# mname = \"facebook/wmt19-en-ru\"\n",
    "# translation_tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "# translation_model = FSMTForConditionalGeneration.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b8032-bf04-440c-aa9a-09fe386e73a8",
   "metadata": {},
   "source": [
    "### Fake detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45ee100-4eb1-49d1-89e1-c4fea56b91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_detection_tokenizer = AutoTokenizer.from_pretrained(\"vikram71198/distilroberta-base-finetuned-fake-news-detection\")\n",
    "fake_detection_model = AutoModelForSequenceClassification.from_pretrained(\"vikram71198/distilroberta-base-finetuned-fake-news-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0b8a73-5506-40eb-afb1-55b3a073a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_and_predict_fake(X_train):\n",
    "    y_pred = np.array([])\n",
    "    \n",
    "    for x_train in tqdm(X_train):\n",
    "        x_train_translated_ids = translation_tokenizer(\n",
    "            x_train,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_ids\n",
    "\n",
    "        x_train_output = translation_model.generate(input_ids=x_train_translated_ids)\n",
    "\n",
    "        x_train_translated = translation_tokenizer.batch_decode(\n",
    "            x_train_output, \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        x_train_fake_detection_input = fake_detection_tokenizer(\n",
    "            x_train_translated, \n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        x_train_fake_detection_output = fake_detection_model(**x_train_fake_detection_input)[\"logits\"]\n",
    "        x_train_fake_detection_detached_output = x_train_fake_detection_output.detach()\n",
    "\n",
    "        fake_detection_softmax = nn.Softmax(dim = 1)\n",
    "        x_train_fake_detection_prediction_probabilities = list(fake_detection_softmax(x_train_fake_detection_detached_output).detach().numpy())\n",
    "\n",
    "        x, y = x_train_fake_detection_prediction_probabilities[0]\n",
    "        print(x_train_fake_detection_prediction_probabilities)\n",
    "        \n",
    "        y_sample = 1 if x < y else 3\n",
    "        y_pred = np.append(y_pred, y_sample)\n",
    "        \n",
    "        print(f\"Prediction for sentence {x_train_translated} is {y_sample}\")\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321662e-eae6-4029-803b-faec1b8fce5a",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3b15db-7040-409e-bd28-eab053d7692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3eed373-f3a7-48c4-8a05-f493f01f2fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[50:100]['Content_processed']\n",
    "y = train_df.iloc[50:100]['Suspicious_Level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33850b6d-0b96-4c49-b7b9-4de43766b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danorel/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "  2%|██▋                                                                                                        | 1/40 [00:01<00:41,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Vladimir Rogov reports that in the Rostov region, air defences have successfully struck two air targets.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▎                                                                                                     | 2/40 [00:02<00:47,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Kreminna fights: the big ones destroy the enemy with C-60 anti-aircrafts. Fighters travel several times a day to perform tasks and destroy targets that are known by drone operators / TASS/.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████                                                                                                   | 3/40 [00:03<00:42,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['The Kremlin claimed that Ankara had broken the agreements by releasing the heads of Azov to Ukraine, but no one informed Russia, declared the RIA of Peskov News.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▋                                                                                                | 4/40 [00:06<01:08,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"Why is it important to support the Russian army? The events of the last few days could seriously undermine the approval of the country's military leadership, but the army is not only the superiors, it's the ordinary guys who were taken out of their families, and the real patriots of the country who were sent by volunteers. The collapse of the army could have catastrophic consequences, which we can see from our history. It's not acceptable. So I decided to make cards that explain this position in an easy way. Help the Russians!\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████▍                                                                                             | 5/40 [00:13<02:04,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['The large-scale exodus of the population of Ukraine will lead to problems in restoring the economy after the end of hostilities in Ukraine. For example, according to information from the public organization EasyBusines and the Centre for Economic Recovery, the failure to return forced migrants to Ukraine will cost only one third of the forced migrants to return to the country in 10 years (to mention also the $45 billion lost to Ukraine). Moreover, according to preliminary estimates, only one third of the displaced migrants will return to Ukraine today (from 3.8 million to 4.7 million forced migrants, of whom approximately 1.4 million are of working age). At best, more and more Ukrainians are finding employment abroad, sending their children to local schools and kindergartens, receiving vocational training to find work there. However, even if most migrants return to grow at a rate of 7 per cent a year, Ukraine needs to attract between 3.1 and 4.5 million workers by 2032.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████████                                                                                           | 6/40 [00:23<03:20,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['The report of the Ministry of Defence of the Russian Federation on the progress of the special military operation (as of 9 July 2023) Part 2. On the Kupjan track, active actions by the Western Group of Forces, fire by operational tactical and army aircraft, fire by artillery, damage to the enemy &apos; s living force and equipment in the areas of Novomlysk, Kamenka, Olshana, Kislovan, Timkovka and Borškiv Kharkiv region; destroyed up to 20 Ukrainian military personnel, two vehicles, a self-propelled artillery installation by Gvazdik, as well as an ammunition depot of the 127th territorial defence brigade in the area of the city of Storica, Harkiv region; on the Herson direction of fire per day destroyed up to 60 Ukrainian soldiers, one tank, defence posts of eight cars, self-propelled Gaubica Gordika, as well as an artillery unit by K777 United States production; on the operational and military air defence brigade, and on the basis of fire by the forces of the armed forces; on the military units of the armed forces of the Russian Federation.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████▋                                                                                        | 7/40 [00:36<04:32,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"Military expert, author of Pancerwafli/Panzerwaffle. The story of the 155-mm supply of cluster munitions to Ukraine is politically more interesting than the military. Indeed, the fundamentally new military capabilities are not giving, and in fact this is such a time, which Americans are making quite openly. So the US President's National Security Adviser, Jake Sullivan, said that the ammunition would serve as a bridge again until the production of conventional munitions can be built up. The problem of the depletion of conventional ammunition stocks has also been confirmed by Byden. At a press conference and in an interview with CNN, the President of the United States said: this war is based on ammunition. And they [the Ukraine] are running out. And they are running away. At the same time, the fact that it is not too pleasant, forced and even dangerous for the troops to re-enact it.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████████▍                                                                                     | 8/40 [00:37<03:08,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"Friends, help us! We're going to publish this message and hope that at least a few people will find themselves concerned!\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████████████████████                                                                                   | 9/40 [00:46<03:30,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"Savva Fedoseev/Plurinational: In Chechnya, police officers severely tortured and robbed military servicemen under contract. Application to open a criminal case that merely described the heinous details of the incident at the end of May 2023. The torturers were subjected to at least three HF 65384. All of them would not retrace (read the creaks), bring a small passage: the Lieutenant Colonel entered the room, who came to the military unit and presented himself to the station chief. When he came in, he said that he would show me 95 years, took me behind the back of the head, put me away so that my body was under 90 degrees. Then another hand would hit me hard in the back of the head. When he had finished, he would say to his staff that he had gone into the room, that he had gone to prayer, and if there were no results, he would take us back. We think it's perfectly understandable that it's all human.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████▌                                                                               | 10/40 [00:46<02:23,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['A minute of humor.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████████████████████▏                                                                            | 11/40 [00:57<03:16,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"It's clear that our task is to kill their personnel. But I don't see them before the end of the 2nd decade of August. I think they're gonna go to that place until 15-20 August. Then they're gonna fall down, and by autumn they're gonna die. Someone's gonna wait that the West is finally gonna talk to us and with the bar hand is gonna let us go? Who's gonna let us go? Who's gonna let us go? Who's go? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it? Who's gonna do it?\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████▊                                                                          | 12/40 [01:00<02:32,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['On 8 July, as at 8 p.m., additional information was received on the operational lines of the PRC on civilian casualties in the cities of the Republic: Pantelmonica: on the street of Stepnoy, 9 men were injured in 1981. The impact of the shelling continues to be reported.'] is 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████████████▍                                                                       | 13/40 [01:04<02:17,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Ukraine launched a missile attack on the Crimean Bridge. Our air defences have not been damaged. Crimeans have reported several explosions in the air (from three to six in various sources). Sergei Aksenov has reported the shooting down of a cruise missile. The movement on the Crimean Bridge has been temporarily suspended.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████████████                                                                     | 14/40 [01:05<01:37,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Erdogan said he looked forward to meeting Putin in August.'] is 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████████████▊                                                                  | 15/40 [01:14<02:13,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Ukraine &apos; s allies continue to dispose of military equipment in order to rearrange the army with Western specimens. The Mi-24 helicopters that the Poles secretly assigned to the U.S.A. should have written off, as well as all weapons to them: it is old and does not fit NATO standards. The MI-24 in the Polish army should be replaced by American Apache, which should be equipped with nearly 100 grand. Although the Poles have not yet received a single copy. Even the eight used vehicles promised by Washington in May as a bonus. They are likely to be granted as a discount for a serious delay in the supply of F-35A Lightning II fighter aircraft. When the Apache still reaches Poland, they are scheduled to be handed over to the 18th Mechanized Division responsible for the defence of the Suvalk Corridor by the NATO Eastern Flang.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████████▍                                                               | 16/40 [01:34<03:54,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['It\\'s not less than ten minutes to prepare an Italian 120-mm mortar system for a 1963-style mortar system, but it\\'s going to take at least ten minutes to prepare the Italian 120-mm mortar system for a 1963-style mortar system. It\\'s going to take at least ten minutes to prepare the electrocutions of a 1963-type mortar. The infantry, which is in the trenches about three kilometres ahead, asks \"to shoot fast because the Russians are attacking.\" Colonel Kohny Yandulski (Serhii Iandulski), 37 years, the commander of the first battalion of the 10-year-old mortar brigade to the north of the United States to the north of Bahmut in the direction of the disputed city of Soledar, thanks to the images transmitted in a continuous manner by the cameras of the two small mavic-3 drones, half an hour ago saw the arrival of the three armoured vehicles, from which the mobile groups of the enemy came forward, the number of the forces that immediately started the offensive. It\\'s evident on the video that these forces are coming out of the selected forces.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████████████████                                                             | 17/40 [01:48<04:15, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['There are more and more new parts in the offensive that have been so carefully hoarded and prepared by the U.S.A. The offensives of our forces under Kupansk and Kremna have forced new brigades to be deployed there. Similarly, the futile fear of a bunch of brigades for two months around the small Blade has led to the sending of a fresh brigade there (but not to say that this changed the course of battle). Comparing the so-called leaked report (it is possible to look at the approximate equipment of the brigades), which allegedly revealed the U.S.S. plans for the offensive - all the new brigades are represented in the image and which of them are already engaged (the location can be seen). The offensive in the south. 33 meh. Brigade. 37 machetes. 47 meh. Brigade. 21 brigade. 47 art. brigade. 32 m. brigade. 31 m. brigade. 23 m. brigade.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████████████▋                                                          | 18/40 [01:50<03:04,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['The cluster munitions that Washington sent to Ukraine do not explode in 14% of cases.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████▎                                                       | 19/40 [01:53<02:23,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['\"Our grandfathers have taught us how to burn German tanks. The 70th regiment of the 58th Army, the BARS-1, which is part of this regiment, and the drone operators of the \"Caribbean Wolfs\" team meet the Germans,\" comments on the video by D. Rogozin.'] is 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████                                                     | 20/40 [01:55<01:47,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Dmitry Steshin laughs at Ukrainian air defences, and the idea is an interesting one that significantly increases the number of shootings.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████████████████████████████████████████▋                                                  | 21/40 [02:07<02:18,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"This is the first time we've had an autobot project that looks like a working version. We've given the guys money (and more specifically, one person has paid for them, receipts and scripts are the same for law enforcement). Five months these people (two people) tell us daily strange things, they don't have enough, they don't have enough, we don't have enough, we don't have enough, we don't have enough money to report from Zaporiza. 1. There's a report to the law enforcement agencies on fraud. 2. These guys had only 100 followers before we gave them information, and they're strongly advised not to give them money. 3. We're not gonna leave this situation alone, and we're gonna thank God we've got those people for the first time and hope for the last time. Alexander, who really liked this project and who paid them for the battalion, who served the same situation and supported our decision to the law enforcement agencies.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████████████▎                                               | 22/40 [02:16<02:19,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"People, there's a request! A woman caring for an injured son at Burdenco Hospital, Resuscitation N 56, Hospital Square 3, Corp. 21, Moscow reported that there are boys lying next to her son, wounded, unconscious; Demin Alexey 1986, Gluško Victor, if I'm not mistaken 1996, Milehin Nikolai 1983 or 85 gr. Maybe someone is looking for these guys from different groups, chat rooms or personal contacts. Please forward this information to their contacts, Sarafan radio often works best and is very fast, thank you for your indifference, maybe it's someone's son, husband or brother. Telephone +7 916 601-67, Olga. +7 (499) 263-55-44 resuscitation, 24 hours a day. +7 (499) 263-55-55 resuscitation, 24 hours a day.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████████████████▉                                             | 23/40 [02:22<02:04,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"And you know who's a truly underrated organization that's just doing a very important job in the current war? Sisters of Mercy. Orthodox young girls, whom any soldier who's in the hospital speaks with love and admiration for having been shot in battle, are the ones who will feed you, give you clean clothes and, in a spiritual sense, wash your feet just for being breast-fed to protect your stepfather. If you're reading this, please accept sincere thanks from me and from every wounded person you've helped. You are truly beautiful girls and women whose beauty is not only of appearance but also of glorious deeds. Thank you, sisters, you are our pride.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████▌                                          | 24/40 [02:24<01:33,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Western junk on the Zaporozhsky track. The U.S.U. is openly afraid to get into foreign technology (Leopards, Bradley). \"As soon as the Russian Federation sees it, everything is coming\" from the testimony of Ukrainian prisoners.'] is 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████▎                                       | 25/40 [02:26<01:09,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence ['Today is a very sad day for us.'] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████████████████▉                                     | 26/40 [02:27<00:49,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"Friends, help us! We're going to publish this message and hope that at least a few people will find themselves concerned!\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████████████████████▌                                  | 27/40 [02:44<01:35,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"An attempt to strike the bridge could be linked to pressure on the Russian leadership to extend the grain deal, which ends on 17 July. But this option is unlikely, because Ukrainian units have been instructed not to work in this direction for the time being. In this situation, the way in which it is presented in the Ukrainian media, especially in the context of the return of the leaders of Azov to Ukraine: supposedly a new reality for Crimea and Russia as a whole. This attack, like in the Rostov region, is more like a part of a strategic information operation whose purpose is to raise the moral and psychological state of the members of the US before a new phase of the offensive. It is no secret that the loss of the U.S.U.'s links involved in the front-line fighting is enormous. Some of the ones on the Zaporizsk track have already been sent to pre-assed. These strikes should convince both Ukrainian units and mercenaries that they are winning. This is a plan to force them into the offensive, rather than to go into the panic from the forward, were already mobilized.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████▏                               | 28/40 [02:49<01:21,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for sentence [\"It doesn't take much for us to survive and win our common cause. Our common cause doesn't ask for huge sums, we don't need anyone to work hard and make serious contributions. Great things always start small. Let your donation be at least 10 or 50 rubles. But if a few concerned people come together, it'll already be a tangible support. SBERBANK map: 4276160925483621. Don't get past it. A couple dozen rubles won't even buy bread, it won't make you poor, but it'll give you a lot of support for all of us.\"] is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████████████▏                               | 28/40 [02:52<01:14,  6.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist(), X\u001b[38;5;241m.\u001b[39miloc[val_index]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m----> 8\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_and_predict_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mf1_score(y_train, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m f1_score_folds\u001b[38;5;241m.\u001b[39mappend(f1_score)\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36mtranslate_and_predict_fake\u001b[0;34m(X_train)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m tqdm(X_train):\n\u001b[1;32m      5\u001b[0m     x_train_translated_ids \u001b[38;5;241m=\u001b[39m translation_tokenizer(\n\u001b[1;32m      6\u001b[0m         x_train,\n\u001b[1;32m      7\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      8\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     )\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m---> 12\u001b[0m     x_train_output \u001b[38;5;241m=\u001b[39m \u001b[43mtranslation_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train_translated_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x_train_translated \u001b[38;5;241m=\u001b[39m translation_tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     15\u001b[0m         x_train_output, \n\u001b[1;32m     16\u001b[0m         skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     x_train_fake_detection_input \u001b[38;5;241m=\u001b[39m fake_detection_tokenizer(\n\u001b[1;32m     20\u001b[0m         x_train_translated, \n\u001b[1;32m     21\u001b[0m         truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     23\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1752\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1746\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1747\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1748\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1750\u001b[0m     )\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/transformers/generation/utils.py:3091\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3089\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m-> 3091\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   3099\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/transformers/models/marian/modeling_marian.py:1419\u001b[0m, in \u001b[0;36mMarianMTModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1398\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1399\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1400\u001b[0m         )\n\u001b[1;32m   1402\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1403\u001b[0m     input_ids,\n\u001b[1;32m   1404\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1418\u001b[0m )\n\u001b[0;32m-> 1419\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1421\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/disinformation_3.10/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fold_number = 1\n",
    "f1_score_folds = []\n",
    "\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index].values.tolist(), X.iloc[val_index].values.tolist()\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    y_pred = translate_and_predict_fake(X_train)\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_train, y_pred, average='macro')\n",
    "    f1_score_folds.append(f1_score)\n",
    "    \n",
    "    print(f\"Fold {fold_number} - F1 Score: {f1_score}\")\n",
    "    print(sklearn.metrics.classification_report(y_pred, y_val))\n",
    "\n",
    "    fold_number += 1\n",
    "    \n",
    "f1_mean_score = sum(f1_score_folds) / num_folds\n",
    "print(f\"F1 Score: {f1_mean_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disinformation_3.10",
   "language": "python",
   "name": "pyenv_disinformation_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
